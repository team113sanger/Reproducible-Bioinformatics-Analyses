---
title: "Making Bioinformatics Analyses Reproducible"
author: "Jamie Billington"
format: 
  revealjs:
    theme: default
    slide-number: true
    transition: none
---

![stong_weak](resources/9msdxj.jpg)

---

## Workshop Overview

1. Why Reproducibility Matters
2. Project Organization
3. Documentation
4. Environment Management
5. Hands-on Project Cleanup + Docker

---

---
## TLDR
If you only take away thee things from today:
- **Use relative paths your projects**
- **Use renv, pip freeze, and conda export**
- The early you tidy up your projects (**and put them in git**) the better!

---

# 1. Why Reproducibility Matters

> "An article about computational science **without a means for reproducing it** in a scientific publication is **not** the scholarship itself, it is merely **advertising** of the scholarship..."
>
> -- Jonathan Buckheit and David Donoho, 1995 

>"Pics or It Didn't Happen"
>
> --  Me, 2025

---
## The carrot: Benefits of reproducible code

* **Scientific integrity**
* **Collaboration**
* **Efficiency**
* **Impact**

---

## The stick: Evolving Journal Requirements

* **2010s**: Code "available upon request"
* **2015-2020**: Code in supplementary materials or repository
* **2020-2025**: Code available as a citeable, persistent repository
* **2025+**: Executable code, containers, and code capsules

---

## Journal Requirements

* **Nature**: Code must be "available in a persistent repository"
* **PLOS**: Code must be in a repository with a DOI
* **Genome Biology**: Code must be under version control and with citeable repository

* Key thing to remember **Authors must deposit all raw data in an appropriate repository prior to peer review**

---

## Current requirements PSA! 

Techinically, all code has to have a "persistent identifier" and be citeable
- Zenodo the easiest way as you can snapshot GitHub "releases"
- Makes them citeable 
![DOI](resources/DOI_repo.png) 

---


## Where things look to be heading

[Capsules](https://codeocean.com/explore?page=1&filter=all)
[CodeOcean](https://codeocean.com/capsule/9835100/tree/v1)

---

# 2. How to get there more easilty: project organization

## Project Structure Principles

Projects should be have a structure that is intuitive for a stranger
1. Have "separation of concerns" (data, code, metadata, documentation)
2. Be self-documentated

[I've compiled a checklist for how to approach this here](https://docs.google.com/document/d/1zi4ECDuNtWIyxddlhv5XLUqyC5kA2517HWgB3K52fak/edit?tab=t.0)

---

---
## What Should You Document?

* **Data**: Sources, cleaning steps, versions
* **Methods**: Algorithms, parameters, rationale
* **Results**: Interpretation, validation, limitations (if not in the paper)
* **Workflow**: Order of operations, dependencies
* **Environment**: Software versions, configurations
--- 

## Directory Structure

```
project/
├── README.md
├── LICENSE
├── data/
│   ├── raw/
│   └── processed/
├── src/
│   ├── preprocessing/
│   ├── analysis/
│   └── visualization/
├── metadata
├── results/
│   ├── figures/
│   └── tables/
└── environment/
```
--- 

## README.md Best Practices

A good README should include:

1. The project title and description
2. Instructions on how to reproduce the analysis
3. Some description of the inputs and outputs
6. Dependencies
7. Contact information

---

## Example README.md

```markdown
# Differential Expression Analysis of COVID-19 Lung Samples

## Overview
This repository contains code for analyzing RNA-seq data from COVID-19 patients in paper X
DOI: djksnkaboufo90120l

## Requirements
- R 4.1.0
- Bioconductor 3.13
- DESeq2, edgeR, limma packages (even better - have an Renv lock file)

## Installation
1. Clone this repository
2. Install R dependencies: `Rscript install_deps.R`

## Usage
1. Retrieve fastq files from EGA study X
2. Run preprocessing: `Rscript src/preprocessing/quality_control.R`
3. Run differential expression: `Rscript src/analysis/diff_exp.R`

## Results
Results will be generated in the `results/` directory.
```

---

## Tips: Naming Conventions

::: {.callout-tip}
Give files names that are lowercase, have no spaces, and are descriptive
  * Good: `preprocess_counts.R`, `differential_expression_analysis.R`
  * Bad: `script1.R`, `DE stuff.R`, `final_FINAL_v2_REALLY_FINAL.R`
:::

---
## Tips: Making your scripts run anywhere

::: {.callout-tip}
Use relative paths instead of absolute paths:
```r
# Good
data_path <- file.path("data", "raw", "counts.csv")
# or
data_path <- here("data", "raw", "counts.csv")

# Bad
data_path <- "/home/user/projects/analysis/data/raw/counts.csv"
```
:::
---


---
## Tips: Cleaning up code

::: {.callout-tip}
Use styler to reformat your R code and make it more consistent + readable
```r
install.packages("styler")
library(styler)

styler::style_dir(".")
```
This will rewrite your code, making spaces constient, splitting up long lines etc.

:::
---


---
## Tips: Testing your code runs for someone else

::: {.callout-tip}
Easiest way is to run your code non-interatively with
```bash
Rscript analysis.R
## or
python3 analysis.py
## or
bash my_script.sh
```
This should complete without throwing an error.
:::
---

## LLM's - your friend or foe?

We live in a time where coding assistants can do some of this for you
- Feed GitHub project directly into Claude, or paste in for feedback from ChatGPT
- Go ahead! But be mindful to scrutinise what you get out... 
- Rule of thumb - use LLMs to solve problems you understand

---

# 4. Environment Management

## The Problem: Dependency Hell

:::: {.columns}
::: {.column width="45%"}
**Common issues**:
- "Works on my machine / the Farm"
- Package version conflicts
- Unspecified requirements
:::

::: {.column width="45%"}
![](https://imgs.xkcd.com/comics/python_environment.png){width=80%}
*Source: XKCD #1987*
:::
::::

Part of the solution: snapshot your environment so that you can share it 
---

## Capturing Environments in R

**Using renv**:

```r
# Initialize project
renv::init()

# Install packages
renv::install("tidyverse")
renv::install("glue")

# Snapshot dependencies
renv::snapshot()
```

Creates an `renv.lock` which records exact package versions you used at the time of creation. 
Never manually write them down them again!

---

## Capturing Environment in Python

**Using pip and a requirements.txtb file **:

```bash
# Generate requirements.txt
pip freeze > requirements.txt
```

**Using virtual environments**:
```bash
# Create virtual environment
python -m venv myenv

# Activate
source myenv/bin/activate  # Linux/Mac

# Install packages
pip install pandas scikit-learn
```

---

## Using Conda for Environment Management

```bash
# Create environment
conda create -n myproject python=3.9

# Activate
conda activate myproject

# Install packages
conda install pandas scikit-learn

# Export environment
conda env export > environment.yml
```

---

# 5. Hands-on Project Reproducibility

## Project Cleanup Checklist

1. **Organization**: Directory structure, file naming
2. **Documentation**: README, in-code comments, notebooks
3. **Environment**: Record the Dependency specification
4. **Code quality**: Consistent style, error handling
5. **Data management**: Raw vs. processed, paths

---


## Introduction to Containers

**What are containers?**
* Isolated, portable environments
* Include OS, dependencies, code
* Consistent across computing environments
* "Write once, run anywhere"
* Better than conda in basically all ways

---

## Docker vs. Singularity

:::: {.columns}
::: {.column width="45%"}
**Docker**:
- Standard in the rest of the computational world
- Not always allowed on HPC (inc. Sanger farm)
- Root privileges (Dangerous!)
- Dockerfile format
:::

::: {.column width="45%"}
**Singularity/Apptainer**:
- HPC-friendly
- No root privileges required
- Can convert Docker containers
- Commonly used in bioinformatics
:::
::::

---
## Why containers rule
Demo time! You should be able to try these in your codespace. 
I've compiled a set of tools we often use in the lab. How easy is it to set them up?
```
docker run quay.io/wtsicgp/valiant:4.0.0 valiant --help
```
```
docker run quay.io/team113sanger/bagel2:f9eedca BAGEL.py --help
```
```
docker run -it quay.io/biocontainers/repeatmasker:4.1.7p1--pl5321hdfd78af_1 repeat-masker --help
```


## How does it work? Anatomy of a Dockerfile

A recipe for all the components a tool requries
```dockerfile
FROM python:3.9-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libz-dev

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy code
COPY src/ /app/src/

# Default command
CMD ["python", "src/main.py"]
```

---

## Exercise: Working with Docker to rebuild environments

**Task**: For a project using:
- R 4.1 with DESeq2, ggplot2, dplyr
- Python 3.9 with pandas, matplotlib, scikit-learn
- samtools, bedtools, and STAR aligner

Create:
1. An renv.lock (for R)
2. A requirements.txt (for Python)
3. A basic Dockerfile

---


---

## Bring Your Own Project!

* Apply what we've learned to your own projects
* Identify areas for improvement
* Work on specific issues
* Get help with implementation


---

## Summary 

It doesn't need to be perfect and you don't need to do it alone!
Think about it earlier rather than later.
Practice -> Embed good habits -> Less extra work at publication.

---

## Finally... my public service announcements

Stop using read.delim() -> used read_delim()
Stop using data.frame() -> use tibble()
Stop using for loops in R -> use lapply() or even better map()

---


